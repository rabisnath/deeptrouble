{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f95ae60",
   "metadata": {},
   "source": [
    "# Bayesian LeNet\n",
    "\n",
    "In this notebook I follow Kumar Shridhar's approach to building a Bayesian Version of LeNet (https://github.com/kumar-shridhar/PyTorch-BayesianCNN/)\n",
    "\n",
    "The goal here is to understand how he generates the estiamtes for aleatoric and epistemic uncertainty from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640ca11",
   "metadata": {},
   "source": [
    "### Importing Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f395db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install --user torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309e5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lenet.py / for the models\n",
    "from torch._C import InferredType\n",
    "from torch.nn import Module # Base class for all nn modules in PyTorch\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a057112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train.py / for training\n",
    "import matplotlib\n",
    "from torch._C import device\n",
    "from torch.functional import broadcast_shapes\n",
    "matplotlib.use(\"Agg\")\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aaec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction / testing\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a070612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys  \n",
    "#!{sys.executable} -m pip install --user torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c49b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import BBBConv2d, BBBLinear, FlattenLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69171e6f",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cae564",
   "metadata": {},
   "source": [
    "### Architecture for LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2cb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet architecture \n",
    "class LeNet(Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        '''\n",
    "        n_channels: the number of channels in the input images\n",
    "        n_classes: the number of unique labels/outputs represented in the dataset\n",
    "\n",
    "        '''\n",
    "        # calling the constructor for the Model class\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # A set of Conv, ReLU and Pool layers\n",
    "        self.conv1 = Conv2d(in_channels=n_channels, out_channels=20, kernel_size=(5,5))\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # A second set of Conv, ReLU and Pool layers\n",
    "        self.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=(5,5))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # A fully connected layer followed by a ReLU\n",
    "        self.fc1 = Linear(in_features=800, out_features=500)\n",
    "        self.relu3 = ReLU()\n",
    "\n",
    "        # Initializing our softmax classifier\n",
    "        self.fc2 = Linear(in_features=500, out_features=n_classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Accepts a batch of input data to feed to the network, \n",
    "        returns the network predictions\n",
    "\n",
    "        '''\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd62c0",
   "metadata": {},
   "source": [
    "### Bayesian Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa934b15",
   "metadata": {},
   "source": [
    "For the bayesian version, we need to: \n",
    "\n",
    "* replace the Conv2d layers with 'BBBConv2d' layers (BBB = Bayes by Backprop)\n",
    "* replace the fully connected layers with 'BBBLinear' layers\n",
    "* replace the default pytorch flatten layer with 'FlattenLayer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4faef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4148020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayesian_LeNet(Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        '''\n",
    "        n_channels: the number of channels in the input images\n",
    "        n_classes: the number of unique labels/outputs represented in the dataset\n",
    "\n",
    "        '''\n",
    "        # calling the constructor for the Model class\n",
    "        super(Bayesian_LeNet, self).__init__()\n",
    "\n",
    "        # A set of Conv, ReLU and Pool layers\n",
    "        self.conv1 = BBBConv2d(in_channels=n_channels, out_channels=20, kernel_size=(5,5))\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # A second set of Conv, ReLU and Pool layers\n",
    "        self.conv2 = BBBConv2d(in_channels=20, out_channels=50, kernel_size=(5,5))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # A fully connected layer followed by a ReLU\n",
    "        self.flatten = FlattenLayer(800)\n",
    "        self.fc1 = BBBLinear(in_features=800, out_features=500)\n",
    "        self.relu3 = ReLU()\n",
    "\n",
    "        # Initializing our softmax classifier\n",
    "        self.fc2 = BBBLinear(in_features=500, out_features=n_classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Accepts a batch of input data to feed to the network, \n",
    "        returns the network predictions\n",
    "\n",
    "        '''\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620b860",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5043daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_class, save_spot='LeNet_example/output/model.pth'):\n",
    "    '''\n",
    "    Takes a class of model to init and train,\n",
    "    as well as a path to save the trained model to\n",
    "    '''\n",
    "    # setting hyperparameters\n",
    "    learning_rate = 1e-3\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    # (1 - train_split) of the training data will be used for validation\n",
    "    train_split = 0.75\n",
    "\n",
    "    # setting training device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # loading the MNIST dataset\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    train_data = MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "    test_data = MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "    # splitting the training data into training and validation data\n",
    "    print(\"Making training and validation sets...\")\n",
    "    n_train = int(train_split * len(train_data))\n",
    "    n_val = len(train_data) - n_train\n",
    "    (train_data, val_data) = random_split(train_data, [n_train, n_val], generator=torch.Generator().manual_seed(84))\n",
    "\n",
    "    # initializing data loaders\n",
    "    train_data_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    val_data_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "    test_data_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # calculating steps per epoch for training+val set\n",
    "    training_steps = len(train_data_loader.dataset) // batch_size\n",
    "    validation_steps = len(val_data_loader.dataset) // batch_size\n",
    "\n",
    "    # initializing the LeNet model\n",
    "    print(\"Initializing model...\")\n",
    "    model = model_class(n_channels=1, n_classes=len(train_data.dataset.classes)).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    # tracking training history\n",
    "    hist = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    # training\n",
    "    print(\"Training the network...\")\n",
    "    t_start = time.time()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # set model to training mode\n",
    "        model.train()\n",
    "        # initializing total training, val loss\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        # initializing the number of correct predictions\n",
    "        train_n_correct = 0\n",
    "        val_n_correct = 0\n",
    "\n",
    "        # training step\n",
    "        for (x, y) in train_data_loader:\n",
    "            # send input to device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "\n",
    "            # perform a forward pass and calc the training loss\n",
    "            prediction = model(x)\n",
    "            loss = loss_fn(prediction, y)\n",
    "\n",
    "            # setting gradients to zero, performing backprop and updating the weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # tracking training loss and num correct\n",
    "            total_train_loss += loss\n",
    "            train_n_correct += (prediction.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # validation step\n",
    "        with torch.no_grad(): # turning off autograd for evaluation\n",
    "            # setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            for (x, y) in val_data_loader:\n",
    "                # send input to device\n",
    "                (x, y) = (x.to(device), y.to(device))\n",
    "\n",
    "                # perform a forward pass and calc the training loss\n",
    "                prediction = model(x)\n",
    "                total_val_loss += loss_fn(prediction, y)\n",
    "                val_n_correct += (prediction.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # adding stats to the history object\n",
    "        \n",
    "        avg_train_loss = total_train_loss / training_steps\n",
    "        avg_val_loss = total_val_loss / validation_steps\n",
    "        train_n_correct = train_n_correct / len(train_data_loader.dataset)\n",
    "        val_n_correct = val_n_correct / len(val_data_loader.dataset)\n",
    "\n",
    "        hist['train_loss'].append(avg_train_loss.cpu().detach().numpy())\n",
    "        hist['train_acc'].append(train_n_correct)\n",
    "        hist['val_loss'].append(avg_val_loss.cpu().detach().numpy())\n",
    "        hist['val_acc'].append(val_n_correct)\n",
    "\n",
    "        # printing\n",
    "        print(\"Epoch {}/{}\".format(i+1, epochs))\n",
    "        print(\"Training Loss: {:.6f}, Training Accuracy: {:.4f}\".format(avg_train_loss, train_n_correct))\n",
    "        print(\"Validation Loss: {:.6f}, Validation Accuracy: {:.4f}\".format(avg_val_loss, val_n_correct))\n",
    "\n",
    "\n",
    "    t_end = time.time()\n",
    "    print(\"Total time: {:.2f}s\".format(t_end - t_start))\n",
    "\n",
    "    print(\"Evaluating trained network...\")\n",
    "\n",
    "    # turn off autograd for testing\n",
    "    with torch.no_grad():\n",
    "        # set model to eval mode\n",
    "        model.eval()\n",
    "        # empty list to store predictions\n",
    "        predictions = []\n",
    "\n",
    "        # looping over testing data\n",
    "        for (x, y) in test_data_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            # making predictions\n",
    "            prediction = model(x)\n",
    "            predictions.extend(prediction.argmax(axis=1).cpu().numpy())\n",
    "\n",
    "\n",
    "    # generate a classification report\n",
    "    print(classification_report(test_data.targets.cpu().numpy(), np.array(predictions), target_names=test_data.classes))\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(hist[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(hist[\"train_acc\"], label=\"train_acc\")\n",
    "    plt.plot(hist[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    #plt.savefig(args.plot)\n",
    "    # serialize the model to disk\n",
    "    torch.save(model, save_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14dcbff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Making training and validation sets...\n",
      "Initializing model...\n",
      "Training the network...\n",
      "Epoch 1/10\n",
      "Training Loss: 0.181599, Training Accuracy: 0.9445\n",
      "Validation Loss: 0.086474, Validation Accuracy: 0.9726\n",
      "Epoch 2/10\n",
      "Training Loss: 0.054114, Training Accuracy: 0.9832\n",
      "Validation Loss: 0.053691, Validation Accuracy: 0.9829\n",
      "Epoch 3/10\n",
      "Training Loss: 0.036515, Training Accuracy: 0.9882\n",
      "Validation Loss: 0.047019, Validation Accuracy: 0.9855\n",
      "Epoch 4/10\n",
      "Training Loss: 0.026521, Training Accuracy: 0.9918\n",
      "Validation Loss: 0.044159, Validation Accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "Training Loss: 0.019976, Training Accuracy: 0.9938\n",
      "Validation Loss: 0.042942, Validation Accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "Training Loss: 0.014728, Training Accuracy: 0.9950\n",
      "Validation Loss: 0.037901, Validation Accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "Training Loss: 0.012730, Training Accuracy: 0.9959\n",
      "Validation Loss: 0.042197, Validation Accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "Training Loss: 0.011732, Training Accuracy: 0.9961\n",
      "Validation Loss: 0.034251, Validation Accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "Training Loss: 0.008901, Training Accuracy: 0.9973\n",
      "Validation Loss: 0.040523, Validation Accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "Training Loss: 0.008945, Training Accuracy: 0.9968\n",
      "Validation Loss: 0.039666, Validation Accuracy: 0.9902\n",
      "Total time: 486.59s\n",
      "Evaluating trained network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       0.10      0.10      0.10       980\n",
      "     1 - one       0.11      0.11      0.11      1135\n",
      "     2 - two       0.11      0.11      0.11      1032\n",
      "   3 - three       0.10      0.10      0.10      1010\n",
      "    4 - four       0.10      0.10      0.10       982\n",
      "    5 - five       0.09      0.08      0.08       892\n",
      "     6 - six       0.09      0.09      0.09       958\n",
      "   7 - seven       0.10      0.10      0.10      1028\n",
      "   8 - eight       0.10      0.10      0.10       974\n",
      "    9 - nine       0.09      0.09      0.09      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.10      0.10      0.10     10000\n",
      "weighted avg       0.10      0.10      0.10     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train(LeNet, save_spot='output/freq_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a6c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Making training and validation sets...\n",
      "Initializing model...\n",
      "Training the network...\n",
      "Epoch 1/10\n",
      "Training Loss: 0.471463, Training Accuracy: 0.8547\n",
      "Validation Loss: 0.141901, Validation Accuracy: 0.9557\n",
      "Epoch 2/10\n",
      "Training Loss: 0.110058, Training Accuracy: 0.9666\n",
      "Validation Loss: 0.080635, Validation Accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "Training Loss: 0.071944, Training Accuracy: 0.9779\n",
      "Validation Loss: 0.071615, Validation Accuracy: 0.9782\n",
      "Epoch 4/10\n",
      "Training Loss: 0.053005, Training Accuracy: 0.9836\n",
      "Validation Loss: 0.060796, Validation Accuracy: 0.9820\n",
      "Epoch 5/10\n",
      "Training Loss: 0.042003, Training Accuracy: 0.9867\n",
      "Validation Loss: 0.053335, Validation Accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "Training Loss: 0.034632, Training Accuracy: 0.9888\n",
      "Validation Loss: 0.052742, Validation Accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "Training Loss: 0.030196, Training Accuracy: 0.9902\n",
      "Validation Loss: 0.054316, Validation Accuracy: 0.9840\n",
      "Epoch 8/10\n",
      "Training Loss: 0.022126, Training Accuracy: 0.9930\n",
      "Validation Loss: 0.066116, Validation Accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "Training Loss: 0.021787, Training Accuracy: 0.9928\n",
      "Validation Loss: 0.048212, Validation Accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "Training Loss: 0.017858, Training Accuracy: 0.9944\n",
      "Validation Loss: 0.048863, Validation Accuracy: 0.9873\n",
      "Total time: 679.79s\n",
      "Evaluating trained network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       0.11      0.11      0.11       980\n",
      "     1 - one       0.13      0.13      0.13      1135\n",
      "     2 - two       0.10      0.11      0.11      1032\n",
      "   3 - three       0.09      0.10      0.09      1010\n",
      "    4 - four       0.10      0.10      0.10       982\n",
      "    5 - five       0.09      0.09      0.09       892\n",
      "     6 - six       0.10      0.10      0.10       958\n",
      "   7 - seven       0.10      0.10      0.10      1028\n",
      "   8 - eight       0.10      0.10      0.10       974\n",
      "    9 - nine       0.10      0.10      0.10      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.10      0.10      0.10     10000\n",
      "weighted avg       0.10      0.10      0.10     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(Bayesian_LeNet, save_spot='output/bayesian_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ca5ee",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac0158",
   "metadata": {},
   "source": [
    "Pasted code from making predictions, getting uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from predict.py\n",
    "model_path = 'LeNet_example/output/freq_model.pth'\n",
    "\n",
    "# setting the device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# loading the MNIST dataset and grabbing 10 random data points\n",
    "print(\"Loading data...\")\n",
    "test_data = MNIST(root='data', train=False, download=True, transform=ToTensor())\n",
    "indxs = np.random.choice(range(len(test_data)), size=(10,))\n",
    "test_data = Subset(test_data, indxs)\n",
    "#initializing test data loader\n",
    "test_data_loader = DataLoader(test_data, batch_size=1)\n",
    "# loading the model\n",
    "model = torch.load(model_path).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630995f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from predict.py:\n",
    "\n",
    "trial_no = 0\n",
    "for (img, label) in test_data_loader:\n",
    "    trail_no += 1\n",
    "    # get original image and ground truth\n",
    "    original_img = img.numpy().squeeze(axis=(0,1))\n",
    "    ground_truth_label = test_data.dataset.classes[label.numpy()[0]]\n",
    "\n",
    "    # send input to device and make prediction\n",
    "    img = img.to(device)\n",
    "    #prediction = model(img)\n",
    "    prediction, epistemic_ucs, aleatoric_ucs = get_uncertainty_per_image(model, img)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e64049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty_per_image(model, input_image, T=15, normalized=False):\n",
    "    \n",
    "    '''\n",
    "    original code:\n",
    "    \n",
    "    input_image = input_image.unsqueeze(0)\n",
    "    input_images = input_image.repeat(T, 1, 1, 1)\n",
    "    net_out, _ = model(input_images)\n",
    "    '''\n",
    "\n",
    "    #net_out = [model(img) for img in input_images]\n",
    "\n",
    "    net_out = model(input_image)\n",
    "\n",
    "    pred = torch.mean(net_out, dim=0).cpu().detach().numpy()\n",
    "    if normalized:\n",
    "        prediction = F.softplus(net_out)\n",
    "        p_hat = prediction / torch.sum(prediction, dim=1).unsqueeze(1)\n",
    "    else:\n",
    "        p_hat = F.softmax(net_out, dim=1)\n",
    "    p_hat = p_hat.detach().cpu().numpy()\n",
    "    p_bar = np.mean(p_hat, axis=0)\n",
    "\n",
    "    temp = p_hat - np.expand_dims(p_bar, 0)\n",
    "    epistemic = np.dot(temp.T, temp) / T\n",
    "    epistemic = np.diag(epistemic)\n",
    "\n",
    "    aleatoric = np.diag(p_bar) - (np.dot(p_hat.T, p_hat) / T)\n",
    "    aleatoric = np.diag(aleatoric)\n",
    "\n",
    "    return pred, epistemic, aleatoric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739a2cd",
   "metadata": {},
   "source": [
    "Grabbing sample image, trying to get a number for uncertainty from the bayesian net\n",
    "\n",
    "Later we'll need to figure out what number to use for uncertainty for the freq net\n",
    "\n",
    "Then we can redo what's in predict.py, i.e. making a nice summary with some examples from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a664ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bayesian_LeNet(\n",
       "  (conv1): BBBConv2d()\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): BBBConv2d()\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): FlattenLayer()\n",
       "  (fc1): BBBLinear()\n",
       "  (relu3): ReLU()\n",
       "  (fc2): BBBLinear()\n",
       "  (logSoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model and setting it to evaluation mode\n",
    "\n",
    "model_path = 'output/bayesian_model.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(model_path).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c87cd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing some data\n",
    "\n",
    "N_datapoints = 10\n",
    "# loading MNIST\n",
    "test_data = MNIST(root='data', train=False, download=True, transform=ToTensor())\n",
    "# Getting N_datapoints random images\n",
    "indxs = np.random.choice(range(len(test_data)), size=(N_datapoints,))\n",
    "test_data = Subset(test_data, indxs)\n",
    "#initializing test data loader\n",
    "test_data_loader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ec693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "644510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img, label) in test_data_loader:\n",
    "    images.append(img)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc7508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36316980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_displayable(img):\n",
    "    displayable = img.numpy().squeeze(axis=(0,1))\n",
    "    displayable = np.dstack([original_img] * 3)\n",
    "    displayable = imutils.resize(original_img, width=128)\n",
    "    return displayable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f31c1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (img, label) in test_data_loader:\n",
    "    plt.clf()\n",
    "    plt.imshow(make_displayable(images[i]))\n",
    "    plt.savefig('example_{}.png'.format(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679cb21",
   "metadata": {},
   "source": [
    "All the images in the test_data_loader are the same?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e748922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working through the get_uncertainty per image method step by step\n",
    "net_out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ccae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
