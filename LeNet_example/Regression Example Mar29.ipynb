{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45060a1",
   "metadata": {},
   "source": [
    "## Setting up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd2c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision.transforms import ToTensor\n",
    "#from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "#from torch._C import device\n",
    "#from torch.functional import broadcast_shapes\n",
    "\n",
    "from lenet import Bayesian_LeNet_R, LeNet_R\n",
    "\n",
    "\n",
    "# commented out dependencies will be deleted when this notebook is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb529ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba48d061",
   "metadata": {},
   "source": [
    "## Setting up our datasets and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad624dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this dataset contains 1000 images of galsim galaxies with the image itself as\n",
    "X with and with the sersic index used to generate each one as Y\n",
    "(the galaxies in the images are comprised of a single sersic profile\n",
    "with 15 arcsec half light radius and varying n)\n",
    "\n",
    "the clean dataset has no noise\n",
    "and the noisy dataset has noise\n",
    "\n",
    "the datasets come in from the .pt files as pytorch Datasets\n",
    "'''\n",
    "clean_galaxies = torch.load('clean_single_component_galaxies_10_values_of_n.pt')\n",
    "#noisy_galaxies = torch.load('noisy_single_component_galaxies_1000_values_of_n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7ac034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_galaxies[0] <- a tuple (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05836dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! - dataset and model hardcoded here\n",
    "data = clean_galaxies\n",
    "MODEL = Bayesian_LeNet_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccf4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "N = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bac4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the ratio of train:val:test data\n",
    "train_portion = 0.6\n",
    "val_portion = 0.2\n",
    "test_portion = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b627e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset in to training, validation and testing\n",
    "n_train = int(train_portion * N)\n",
    "n_val = int(val_portion * N)\n",
    "n_test = int(test_portion * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a4c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_train + n_val + n_test != N: print(\"Warning: some datapoints were excluded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07152a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, val_data, test_data) = random_split(data, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88a6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dataloaders\n",
    "train_data_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ec1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating steps per epoch for training+val set\n",
    "# these numbers are only used for keeping record of the \n",
    "# average training + val loss\n",
    "# they aren't directly used in training\n",
    "training_steps = len(train_data) // batch_size\n",
    "validation_steps = len(val_data) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47c93d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d86b4",
   "metadata": {},
   "source": [
    "## Initializing our model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4538769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MODEL(n_channels=1).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3def576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking training history\n",
    "hist = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_error\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_error\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e43b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 1/10\n",
      "Training Loss: 139.583740234375, Training Error: tensor([13.9808, 12.2031, 11.3143, 11.7587, 10.4255, 10.8699],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 12.392898559570312, Validation Error: tensor([1.2606, 4.8163])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 2/10\n",
      "Training Loss: 62.91098403930664, Training Error: tensor([ 8.2926,  6.5148, 10.0705,  6.9593,  7.4037,  7.8482],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 15.765053749084473, Validation Error: tensor([1.7725, 5.3281])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 3/10\n",
      "Training Loss: 100.07074737548828, Training Error: tensor([ 9.4930, 10.3819, 12.1598,  8.6041,  9.0486,  9.9375],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 70.06781005859375, Validation Error: tensor([9.9576, 6.4018])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 4/10\n",
      "Training Loss: 14.476273536682129, Training Error: tensor([3.6276, 5.8499, 2.7387, 2.2942, 3.1831, 4.0720],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 8.032942771911621, Validation Error: tensor([0.4298, 3.9851])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 5/10\n",
      "Training Loss: 1.6426348686218262, Training Error: tensor([2.7930, 1.0153, 0.7625, 0.5708, 0.3181, 0.1264],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 4.485803604125977, Validation Error: tensor([0.6265, 2.9290])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 6/10\n",
      "Training Loss: 4.278457164764404, Training Error: tensor([1.2767, 3.9428, 0.3880, 1.7211, 0.8324, 2.1654],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 7.061357498168945, Validation Error: tensor([3.7528, 0.1973])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 7/10\n",
      "Training Loss: 4.848001480102539, Training Error: tensor([0.9902, 1.4347, 0.5458, 1.8791, 4.1013, 2.3236],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 4.904728412628174, Validation Error: tensor([0.4571, 3.0985])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 8/10\n",
      "Training Loss: 4.9018073081970215, Training Error: tensor([2.3378, 1.4490, 4.1156, 0.5601, 1.8934, 1.0045],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 19.572399139404297, Validation Error: tensor([5.8290, 2.2733])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 9/10\n",
      "Training Loss: 2.9608843326568604, Training Error: tensor([1.2822, 3.5044, 0.3934, 0.8378, 1.7266, 0.0511],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 16.220449447631836, Validation Error: tensor([5.3917, 1.8360])\n",
      "Shape of input to forward method:  torch.Size([6, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([6, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([6, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([6, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([6, 6])\n",
      "Shape of output:  torch.Size([6])\n",
      "X shape:  torch.Size([6, 1, 495, 495])\n",
      "Y shape:  torch.Size([6])\n",
      "Prediction shape:  torch.Size([6])\n",
      "Error shape:  torch.Size([6])\n",
      "Shape of input to forward method:  torch.Size([2, 1, 495, 495])\n",
      "Shape of x before 2nd convolution:  torch.Size([2, 20, 245, 245])\n",
      "Shape of x before flatten layer:  torch.Size([2, 50, 120, 120])\n",
      "Shape of x after flatten layer / before FC 1:  torch.Size([2, 720000])\n",
      "Shape of x before passing to final FC layer:  torch.Size([2, 6])\n",
      "Shape of output:  torch.Size([2])\n",
      "Epoch 10/10\n",
      "Training Loss: 5.62421178817749, Training Error: tensor([1.6310, 2.5199, 0.7421, 2.0754, 4.2976, 1.1865],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Validation Loss: 6.654708385467529, Validation Error: tensor([0.0915, 3.6471])\n",
      "CPU times: user 28.2 s, sys: 3.88 s, total: 32.1 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(epochs):\n",
    "        # set model to training mode\n",
    "        model.train()\n",
    "        # initializing total training, val loss\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        # initializing total error (in units matching the sersic index)\n",
    "        total_train_error = 0\n",
    "        total_val_error = 0\n",
    "\n",
    "        # training step\n",
    "        for (x, y) in train_data_loader:\n",
    "            # send input to device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "\n",
    "            # perform a forward pass and calc the training loss\n",
    "            prediction = model(x)\n",
    "            loss = loss_fn(prediction, y)\n",
    "            error = abs(prediction - y)\n",
    "            print(\"X shape: \", x.shape)\n",
    "            print(\"Y shape: \", y.shape)\n",
    "            print(\"Prediction shape: \", prediction.shape)\n",
    "            print(\"Error shape: \", error.shape)\n",
    "\n",
    "            # setting gradients to zero, performing backprop and updating the weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # tracking training loss and num correct\n",
    "            total_train_loss += loss\n",
    "            total_train_error += error\n",
    "\n",
    "        # validation step\n",
    "        with torch.no_grad(): # turning off autograd for evaluation\n",
    "            # setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            for (x, y) in val_data_loader:\n",
    "                # send input to device\n",
    "                (x, y) = (x.to(device), y.to(device))\n",
    "\n",
    "                # perform a forward pass and calc the training loss\n",
    "                prediction = model(x)\n",
    "                loss = loss_fn(prediction, y)\n",
    "                error = abs(prediction - y)\n",
    "                total_val_loss += loss\n",
    "                total_val_error += error\n",
    "\n",
    "        # adding stats to the history object\n",
    "        \n",
    "        avg_train_loss = total_train_loss #/ training_steps\n",
    "        avg_val_loss = total_val_loss #/ validation_steps\n",
    "        avg_train_error = total_train_error #/ len(train_data_loader.dataset)\n",
    "        avg_val_error = total_val_error #/ len(val_data_loader.dataset)\n",
    "\n",
    "        hist['train_loss'].append(avg_train_loss.cpu().detach().numpy())\n",
    "        hist['train_error'].append(avg_train_error)\n",
    "        hist['val_loss'].append(avg_val_loss.cpu().detach().numpy())\n",
    "        hist['val_error'].append(avg_val_error)\n",
    "\n",
    "        # printing\n",
    "        print(\"Epoch {}/{}\".format(i+1, epochs))\n",
    "        print(\"Training Loss: {}, Training Error: {}\".format(avg_train_loss, avg_train_error))\n",
    "        print(\"Validation Loss: {}, Validation Error: {}\".format(avg_val_loss, avg_val_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b93ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Bayesian_LeNet_Regression_Mar29.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d7a2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to self, when cleaning up this notebook into scripts, change the 'unknown number' in the bayesian lenet R class, \n",
    "# figure out what it is, and in a cell above, call the network with the params inserted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
